# 快速搭建本地离线AI智能体

搭建本地离线AI智能体通常涉及数据准备、模型训练、优化和部署等复杂步骤。然而，借助 FlyEnv，你可以在几分钟内快速搭建一个本地离线AI智能体，且无需准备数据和训练。以下是详细指南：

## 1. 安装Ollama

在Ollama模块中安装ollama。

![Ollama安装界面](https://oss.macphpstudy.com/image/ollama-1.png)

## 2. 启动Ollama服务

在Ollama模块中启动ollama服务。

![Ollama服务启动界面](https://oss.macphpstudy.com/image/ollama-2.png)

## 3. 安装模型

在Ollama模块中安装要使用的模型，例如：deepseek-r1、llama3.3、phi4、qwen2.5、mixtral。建议选择最大模型尺寸为电脑内存的一半左右。

![模型安装界面](https://oss.macphpstudy.com/image/ollama-3.png)

## 4. 开启AI助手显示

在设置中开启显示AI助手。

![AI助手显示设置](https://oss.macphpstudy.com/image/ollama-4.png)

## 5. 进入AI助手界面

点击右下角AI助手图标，进入AI助手界面。

![AI助手界面](https://oss.macphpstudy.com/image/ollama-5.png)

## 6. 设置Ollama服务

点击设置按钮，设置Ollama服务的API地址。可以是本机地址，也可以是局域网/公共网络地址。地址设置后，会获取此地址已安装的全部模型，选择要使用的模型。

对于团队来说，可以使用一台高配电脑作为Ollama服务的主机，其余人员可以使用此主机地址，以获取更好的效果。

![Ollama服务设置](https://oss.macphpstudy.com/image/ollama-6.png)

## 7. 开启新聊天

设置完成后，点击新建聊天按钮，开启新的聊天。

![新建聊天界面](https://oss.macphpstudy.com/image/ollama-7.png)
![聊天界面](https://oss.macphpstudy.com/image/ollama-8.png)

## 8. AI助手回复操作

AI助手回复的内容可以朗读和复制。

![AI助手回复操作](https://oss.macphpstudy.com/image/ollama-9.png)

## 9. 更改AI助手角色设定

点击此处图标，可更改AI助手的角色设定。系统已经内置了很多预设角色，用户也可自行添加角色。

![AI助手角色设定](https://oss.macphpstudy.com/image/ollama-10.png)

## 总结

借助 FlyEnv，你无需准备数据或训练模型，即可快速搭建本地离线AI智能体，轻松体验AI的强大能力，迈入智能时代。

### 核心优势回顾：
- **快速搭建**：几分钟内完成 AI 智能体的搭建。
- **无需数据与训练**：直接使用预训练模型，节省时间和资源。
- **完全离线**：保护数据隐私，适合对安全性要求高的场景。

立即尝试 FlyEnv，开启你的 AI 之旅吧！